{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pWbToC1_lNcO"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.callbacks import EarlyStopping\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7io6pjllVST",
        "outputId": "96e6d6e0-1c77-4400-8bd7-0b9fdcf90e4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to the range [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "WqMQ3ggjlubq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to categorical one-hot encoding\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "K9gH7XdTmDwg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training dataset into validation and partial training sets\n",
        "val_images = X_train[:10000]\n",
        "partial_images = X_train[10000:]\n",
        "\n",
        "val_labels = y_train[:10000]\n",
        "partial_labels = y_train[10000:]"
      ],
      "metadata": {
        "id": "NAkYenwtmFb0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_custom_cnn_model(f1, f2, f3, kernel_size, activation_1, activation_2, dropout_1, dropout_2, optimizer, epochs):\n",
        "    custom_model = models.Sequential()\n",
        "    custom_model.add(layers.Conv2D(filters=f1, kernel_size=kernel_size, activation=activation_1, input_shape=(32, 32, 3)))\n",
        "    custom_model.add(layers.Conv2D(filters=f1, kernel_size=kernel_size, activation=activation_1))\n",
        "    custom_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    custom_model.add(layers.Conv2D(filters=f2, kernel_size=kernel_size, activation=activation_2))\n",
        "    custom_model.add(layers.Conv2D(filters=f2, kernel_size=kernel_size, activation=activation_2))\n",
        "    custom_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    custom_model.add(layers.Flatten())\n",
        "    custom_model.add(layers.Dropout(rate=dropout_1))\n",
        "    custom_model.add(layers.Dense(units=f3, activation=activation_2))\n",
        "    custom_model.add(layers.Dropout(rate=dropout_2))\n",
        "    custom_model.add(layers.Dense(units=10, activation=\"softmax\"))\n",
        "\n",
        "    custom_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=7)\n",
        "    custom_model.fit(partial_images, partial_labels, validation_data=(val_images, val_labels), epochs=epochs, batch_size=100, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    return custom_model"
      ],
      "metadata": {
        "id": "Bkz_y6PAmJhx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "    parameters = {}\n",
        "    parameters[\"filters_1\"] = random.choice([32, 64])\n",
        "    parameters[\"filters_2\"] = random.choice([64, 128])\n",
        "    parameters[\"filters_3\"] = random.choice([128, 256, 512])\n",
        "    parameters[\"kernel_size\"] = random.choice([(3, 3), (5, 5)])\n",
        "    parameters[\"activation_1\"] = random.choice([\"relu\", \"sigmoid\", \"tanh\"])\n",
        "    parameters[\"activation_2\"] = random.choice([\"relu\", \"sigmoid\", \"tanh\"])\n",
        "    parameters[\"dropout_1\"] = round(random.uniform(0.1, 0.5), 1)\n",
        "    parameters[\"dropout_2\"] = round(random.uniform(0.1, 0.5), 1)\n",
        "    parameters[\"optimizer\"] = random.choice([\"adam\", \"adagrad\", \"SGD\", \"rmsprop\"])\n",
        "    parameters[\"epochs\"] = np.random.randint(50, 100)\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "M633dNZamyoy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_population(n):\n",
        "    population = []\n",
        "    for _ in range(n):\n",
        "        chromosome = initialize_parameters()\n",
        "        population.append(chromosome)\n",
        "    return population"
      ],
      "metadata": {
        "id": "mqwqm4D-n3PH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fitness(model):\n",
        "    evaluation_metrics = model.evaluate(X_test, y_test)\n",
        "    accuracy = evaluation_metrics[1]\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "1vZra8RLn5FW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selection(population_fitness):\n",
        "    total = sum(population_fitness)\n",
        "    percentage = [round((x / total) * 100) for x in population_fitness]\n",
        "    selection_wheel = []\n",
        "    for pop_index, num in enumerate(percentage):\n",
        "        selection_wheel.extend([pop_index] * num)\n",
        "    parent1_ind = random.choice(selection_wheel)\n",
        "    parent2_ind = random.choice(selection_wheel)\n",
        "    return [parent1_ind, parent2_ind]"
      ],
      "metadata": {
        "id": "6dG1-Lirn6zK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossover(parent1, parent2):\n",
        "    child1 = {}\n",
        "    child2 = {}\n",
        "\n",
        "    child1[\"filters_1\"] = random.choice([parent1[\"filters_1\"], parent2[\"filters_1\"]])\n",
        "    child1[\"filters_2\"] = random.choice([parent1[\"filters_2\"], parent2[\"filters_2\"]])\n",
        "    child1[\"filters_3\"] = random.choice([parent1[\"filters_3\"], parent2[\"filters_3\"]])\n",
        "\n",
        "    child2[\"filters_1\"] = random.choice([parent1[\"filters_1\"], parent2[\"filters_1\"]])\n",
        "    child2[\"filters_2\"] = random.choice([parent1[\"filters_2\"], parent2[\"filters_2\"]])\n",
        "    child2[\"filters_3\"] = random.choice([parent1[\"filters_3\"], parent2[\"filters_3\"]])\n",
        "\n",
        "    child1[\"kernel_size\"] = random.choice([parent1[\"kernel_size\"], parent2[\"kernel_size\"]])\n",
        "    child2[\"kernel_size\"] = random.choice([parent1[\"kernel_size\"], parent2[\"kernel_size\"]])\n",
        "\n",
        "    child1[\"activation_1\"] = parent1[\"activation_2\"]\n",
        "    child2[\"activation_1\"] = parent2[\"activation_2\"]\n",
        "\n",
        "    child1[\"activation_2\"] = parent2[\"activation_1\"]\n",
        "    child2[\"activation_2\"] = parent1[\"activation_1\"]\n",
        "\n",
        "    child1[\"dropout_1\"] = parent1[\"dropout_1\"]\n",
        "    child2[\"dropout_1\"] = parent2[\"dropout_1\"]\n",
        "\n",
        "    child1[\"dropout_2\"] = parent2[\"dropout_2\"]\n",
        "    child2[\"dropout_2\"] = parent1[\"dropout_2\"]\n",
        "\n",
        "    child1[\"optimizer\"] = parent2[\"optimizer\"]\n",
        "    child2[\"optimizer\"] = parent1[\"optimizer\"]\n",
        "\n",
        "    child1[\"epochs\"] = parent1[\"epochs\"]\n",
        "    child2[\"epochs\"] = parent2[\"epochs\"]\n",
        "\n",
        "    return [child1, child2]"
      ],
      "metadata": {
        "id": "WLyl2C5Soclb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutation(chromosome):\n",
        "    flag = random.randint(0, 40)\n",
        "    if flag <= 20:\n",
        "        chromosome[\"epochs\"] += random.randint(0, 10)\n",
        "    return chromosome"
      ],
      "metadata": {
        "id": "Oc53_h-3olNC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generations = 3\n",
        "threshold = 90\n",
        "num_pop = 10"
      ],
      "metadata": {
        "id": "oS6UkL45o27V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population = generate_population(num_pop)\n",
        "\n",
        "for generation in range(generations):\n",
        "    population_fitness = []\n",
        "    for chromosome in population:\n",
        "        filters_1 = chromosome[\"filters_1\"]\n",
        "        filters_2 = chromosome[\"filters_2\"]\n",
        "        filters_3 = chromosome[\"filters_3\"]\n",
        "        kernel_size = chromosome[\"kernel_size\"]\n",
        "        activation_1 = chromosome[\"activation_1\"]\n",
        "        activation_2 = chromosome[\"activation_2\"]\n",
        "        dropout_1 = chromosome[\"dropout_1\"]\n",
        "        dropout_2 = chromosome[\"dropout_2\"]\n",
        "        optimizer = chromosome[\"optimizer\"]\n",
        "        epochs = chromosome[\"epochs\"]\n",
        "\n",
        "        try:\n",
        "            model = create_custom_cnn_model(filters_1, filters_2, filters_3, kernel_size, activation_1, activation_2, dropout_1, dropout_2, optimizer, epochs)\n",
        "            acc = evaluate_fitness(model)\n",
        "            print(\"Parameters: \", chromosome)\n",
        "            print(\"Accuracy: \", round(acc, 3))\n",
        "        except:\n",
        "            acc = 0\n",
        "            print(\"Parameters: \", chromosome)\n",
        "            print(\"Invalid parameters - Build fail\")\n",
        "\n",
        "        population_fitness.append(acc)\n",
        "\n",
        "    parents_ind = selection(population_fitness)\n",
        "    parent1 = population[parents_ind[0]]\n",
        "    parent2 = population[parents_ind[1]]\n",
        "\n",
        "    children = crossover(parent1, parent2)\n",
        "    child1 = mutation(children[0])\n",
        "    child2 = mutation(children[1])\n",
        "\n",
        "    population.append(child1)\n",
        "    population.append(child2)\n",
        "\n",
        "    print(\"Generation \", generation + 1, \" Outcome: \")\n",
        "\n",
        "    if max(population_fitness) >= threshold:\n",
        "        print(\"Obtained desired accuracy: \", max(population_fitness))\n",
        "        break\n",
        "    else:\n",
        "        print(\"Maximum accuracy in generation {}: {}\".format(generation + 1, max(population_fitness)))\n",
        "\n",
        "    first_min = min(population_fitness)\n",
        "    first_min_ind = population_fitness.index(first_min)\n",
        "    population.remove(population[first_min_ind])\n",
        "    second_min = min(population_fitness)\n",
        "    second_min_ind = population_fitness.index(second_min)\n",
        "    population.remove(population[second_min_ind])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdBM42kppBJh",
        "outputId": "9b9b330e-cbe8-490e-e5ff-8eeaa49e67b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 1.3515 - accuracy: 0.5037\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 64, 'filters_3': 128, 'kernel_size': (5, 5), 'activation_1': 'sigmoid', 'activation_2': 'relu', 'dropout_1': 0.2, 'dropout_2': 0.2, 'optimizer': 'adagrad', 'epochs': 93}\n",
            "Accuracy:  0.504\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8867 - accuracy: 0.6993\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 64, 'filters_3': 256, 'kernel_size': (3, 3), 'activation_1': 'relu', 'activation_2': 'tanh', 'dropout_1': 0.1, 'dropout_2': 0.1, 'optimizer': 'SGD', 'epochs': 59}\n",
            "Accuracy:  0.699\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5505 - accuracy: 0.4277\n",
            "Parameters:  {'filters_1': 64, 'filters_2': 64, 'filters_3': 512, 'kernel_size': (3, 3), 'activation_1': 'tanh', 'activation_2': 'sigmoid', 'dropout_1': 0.2, 'dropout_2': 0.1, 'optimizer': 'adagrad', 'epochs': 65}\n",
            "Accuracy:  0.428\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3104 - accuracy: 0.1000\n",
            "Parameters:  {'filters_1': 64, 'filters_2': 64, 'filters_3': 128, 'kernel_size': (5, 5), 'activation_1': 'tanh', 'activation_2': 'tanh', 'dropout_1': 0.5, 'dropout_2': 0.3, 'optimizer': 'rmsprop', 'epochs': 81}\n",
            "Accuracy:  0.1\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8410 - accuracy: 0.7116\n",
            "Parameters:  {'filters_1': 64, 'filters_2': 128, 'filters_3': 512, 'kernel_size': (3, 3), 'activation_1': 'tanh', 'activation_2': 'tanh', 'dropout_1': 0.2, 'dropout_2': 0.4, 'optimizer': 'adam', 'epochs': 87}\n",
            "Accuracy:  0.712\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9916 - accuracy: 0.6567\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 64, 'filters_3': 512, 'kernel_size': (5, 5), 'activation_1': 'sigmoid', 'activation_2': 'tanh', 'dropout_1': 0.4, 'dropout_2': 0.2, 'optimizer': 'rmsprop', 'epochs': 78}\n",
            "Accuracy:  0.657\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1252 - accuracy: 0.6012\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 64, 'filters_3': 256, 'kernel_size': (5, 5), 'activation_1': 'tanh', 'activation_2': 'tanh', 'dropout_1': 0.2, 'dropout_2': 0.1, 'optimizer': 'adagrad', 'epochs': 98}\n",
            "Accuracy:  0.601\n",
            "Parameters:  {'filters_1': 64, 'filters_2': 64, 'filters_3': 256, 'kernel_size': (5, 5), 'activation_1': 'relu', 'activation_2': 'tanh', 'dropout_1': 0.4, 'dropout_2': 0.3, 'optimizer': 'adam', 'epochs': 77}\n",
            "Invalid parameters - Build fail\n",
            "Parameters:  {'filters_1': 64, 'filters_2': 128, 'filters_3': 128, 'kernel_size': (3, 3), 'activation_1': 'sigmoid', 'activation_2': 'tanh', 'dropout_1': 0.3, 'dropout_2': 0.2, 'optimizer': 'SGD', 'epochs': 97}\n",
            "Invalid parameters - Build fail\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 128, 'filters_3': 512, 'kernel_size': (3, 3), 'activation_1': 'sigmoid', 'activation_2': 'tanh', 'dropout_1': 0.2, 'dropout_2': 0.1, 'optimizer': 'adam', 'epochs': 90}\n",
            "Invalid parameters - Build fail\n",
            "Generation  1  Outcome: \n",
            "Maximum accuracy in generation 1: 0.7116000056266785\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 64, 'filters_3': 128, 'kernel_size': (5, 5), 'activation_1': 'sigmoid', 'activation_2': 'relu', 'dropout_1': 0.2, 'dropout_2': 0.2, 'optimizer': 'adagrad', 'epochs': 93}\n",
            "Invalid parameters - Build fail\n",
            "Parameters:  {'filters_1': 32, 'filters_2': 64, 'filters_3': 256, 'kernel_size': (3, 3), 'activation_1': 'relu', 'activation_2': 'tanh', 'dropout_1': 0.1, 'dropout_2': 0.1, 'optimizer': 'SGD', 'epochs': 59}\n",
            "Invalid parameters - Build fail\n",
            "Parameters:  {'filters_1': 64, 'filters_2': 64, 'filters_3': 512, 'kernel_size': (3, 3), 'activation_1': 'tanh', 'activation_2': 'sigmoid', 'dropout_1': 0.2, 'dropout_2': 0.1, 'optimizer': 'adagrad', 'epochs': 65}\n",
            "Invalid parameters - Build fail\n"
          ]
        }
      ]
    }
  ]
}